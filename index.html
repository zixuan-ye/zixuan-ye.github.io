<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zixuan Ye's Homepage</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="icon" href="assets/icon.png" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    
    <link rel="stylesheet" href="style.css">

</head>
<body>

    <div class="page-container">
        
        <nav class="sidebar">
            <div class="sidebar-header">
                <img src="assets/me.png" alt="Zixuan Ye">
                <h3>Zixuan Ye</h3>
                <p>Âè∂Á¥´Áíá</p>
            </div>
            <ul class="sidebar-nav">
                <li><a href="#biography" class="nav-link active"><i class="fa-solid fa-house fa-fw"></i> About Me</a></li>
                <li><a href="#news" class="nav-link"><i class="fa-solid fa-newspaper fa-fw"></i> News</a></li>
                <li><a href="#education" class="nav-link"><i class="fa-solid fa-graduation-cap fa-fw"></i> Education</a></li>
                <li><a href="#experience" class="nav-link"><i class="fa-solid fa-briefcase fa-fw"></i> Experience</a></li>
                <li><a href="#publications" class="nav-link"><i class="fa-solid fa-book-open fa-fw"></i> Publications</a></li>
                <li><a href="#honors" class="nav-link"><i class="fa-solid fa-trophy fa-fw"></i> Honors</a></li>
            </ul>
            <div class="sidebar-footer">
                <p>&copy; 2025 Zixuan Ye</p>
            </div>
        </nav>

        <main class="content">
            <header class="profile-header">
                <h1>Zixuan Ye</h1>
                <p class="subtitle">PhD Student in Artificial Intelligence, HKUST</p>
            </header>

            <section id="biography">
                <h2><i class="fa-solid fa-user"></i> About Me</h2>
                <p>
                    Hiüëã! I'm Zixuan Ye (Âè∂Á¥´Áíá), a first-year Ph.D. student at the Hong Kong University of Science and Technology, affilated with the <a href="https://c4g-hkust.github.io/" target="_blank" rel="noopener noreferrer">C4 Group</a> supervised by <a href="https://whluo.github.io/" target="_blank" rel="noopener noreferrer">Wenhan Luo</a>.
                    I obtained both my Bachelor's and Master's degrees from Huazhong University of Science and Technology, supervised by <a href="https://sites.google.com/site/poppinace/" target="_blank" rel="noopener noreferrer">Hao Lu</a> and <a href="https://scholar.google.com.sg/citations?user=396o2BAAAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Zhiguo Cao</a>. My research interests lie in GenAI, especially in video generation and editing. 
                </p>    
                <p>
                    I'm always open to new collaborations, so please feel free to get in touchüôã!
                </p>    
            </section>
            
            <section id="news">
                <h2><i class="fa-solid fa-newspaper"></i> News</h2>
                <div class="news-container">
                    <ul class="news-list">
                        <li class="news-item">
                            <span class="news-date">Jun. 2025</span>
                            <div class="news-text">We release <a href="https://zixuan-ye.github.io/UNIC/"> UNIC</a> and <a href="https://fulldit2.github.io/"> FullDiT2</a>, which explore the in-context conditioning potential in video editing and the accelaration of the framework.</div>
                        </li>
                        <li class="news-item">
                            <span class="news-date">Feb. 2025</span>
                            <div class="news-text"><a href="https://zixuan-ye.github.io/stylemaster/">StyleMaster</a> accepted to CVPR 2025.</div>
                        </li>
                    </ul>
                </div>
            </section>

            

            <section id="education">
                <h2><i class="fa-solid fa-graduation-cap"></i> Education</h2>
                <ul class="timeline">
                    <li class="timeline-item">
                        <div class="timeline-logo">
                            <img src="assets/hkust.jpeg" alt="HKUST Logo">
                        </div>
                        <div class="timeline-body">
                            <h3>Ph.D. in Artificial Intelligence</h3>
                            <p class="institution">Hong Kong University of Science and Technology (HKUST)</p>
                            <p class="details"><em>Supervisor: <a href="https://whluo.github.io/" target="_blank" rel="noopener noreferrer">Wenhan Luo</a></em></p>
                        </div>
                        <div class="timeline-date">Sep 2025 - Present</div>
                    </li>
                    <li class="timeline-item">
                        <div class="timeline-logo">
                            <img src="assets/HUST.png" alt="HUST Logo">
                        </div>
                        <div class="timeline-body">
                            <h3>Master in Intelligent Science and Technology</h3>
                            <p class="institution">Huazhong University of Science and Technology (HUST)</p>
                            <p class="details"><em>Supervisors: <a href="https://sites.google.com/site/poppinace/" target="_blank" rel="noopener noreferrer">Hao Lu</a> and <a href="https://scholar.google.com.sg/citations?user=396o2BAAAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Zhiguo Cao</a></em></p>
                        </div>
                        <div class="timeline-date">Sep 2022 - Jun 2025</div>
                    </li>
                    <li class="timeline-item">
                        <div class="timeline-logo">
                            <img src="assets/HUST.png" alt="HUST Logo">
                        </div>
                        <div class="timeline-body">
                            <h3>B.Eng in Automation</h3>
                            <p class="institution">Huazhong University of Science and Technology (HUST)</p>
                        </div>
                        <div class="timeline-date">Sep 2018 - Jul 2022</div>
                    </li>
                </ul>
            </section>

            <section id="experience">
                <h2><i class="fa-solid fa-briefcase"></i> Experience</h2>
                <ul class="timeline">
                    <li class="timeline-item">
                        <div class="timeline-logo">
                            <img src="assets/kuaishou.png" alt="Kuaishou Logo">
                        </div>
                        <div class="timeline-body">
                            <h3>Research Intern</h3>
                            <p class="institution"><a href="https://www.kuaishou.com/en" target="_blank" rel="noopener noreferrer">Kuaishou Technology</a></p>
                            <p class="details"><em>Topic: Controllable video generation: video editing.</em></p>
                            <p class="details"><em>Advisors: <a href="https://liuquande.github.io/" target="_blank" rel="noopener noreferrer">Dr. Quande Liu</a> and <a href="https://xinntao.github.io/" target="_blank" rel="noopener noreferrer">Dr. Xintao Wang</a>.</em></p>
                        </div>
                        <div class="timeline-date">Feb 2025 - present</div>
                    </li>
                    <li class="timeline-item">
                        <div class="timeline-logo">
                            <img src="assets/kuaishou.png" alt="Kuaishou Logo">
                        </div>
                        <div class="timeline-body">
                            <h3>Research Intern</h3>
                            <p class="institution"><a href="https://www.kuaishou.com/en" target="_blank" rel="noopener noreferrer">Kuaishou Technology</a></p>
                            <p class="details"><em>Topic: Controllable video generation: video stylization.</em></p>
                            <p class="details"><em>Advisors: <a href="https://scholar.google.com/citations?user=BMPobCoAAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Dr. Huijuan Huang</a> and <a href="https://xinntao.github.io/" target="_blank" rel="noopener noreferrer">Dr. Xintao Wang</a>.</em></p>
                        </div>
                        <div class="timeline-date">Jul 2024 - Feb 2025</div>
                    </li>
                </ul>
            </section>

            <section id="publications">
                <h2><i class="fa-solid fa-book-open"></i> Publications</h2>
                
                <h3>Selected Preprint</h3>
                <ul class="publication-list">
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">UNIC: Unified In-Context Video Editing</div>
                            <div class="authors"><b>Zixuan Ye</b>*, Xuanhua He*, Quande Liu, Qiulin Wang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, Qifeng Chen, Wenhan Luo</div>
                            <div class="venue"><em>arXiv:2506.04216</em></div>
                            <div class="publication-links">
                                <a href="https://zixuan-ye.github.io/UNIC/" target="_blank" rel="noopener noreferrer" class="link-button project">
                                    <i class="fa-solid fa-globe"></i> Project
                                </a>
                                <a href="https://arxiv.org/abs/2506.04216" target="_blank" rel="noopener noreferrer" class="link-button pdf">
                                    <i class="fa-solid fa-file-pdf"></i> PDF
                                </a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/unic_demo.gif" alt="Preview for UNIC">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers</div>
                            <div class="authors">Xuanhua He, Quande Liu, <b>Zixuan Ye</b>, Weicai Ye, Qiulin Wang, Xintao Wang, Qifeng Chen, Pengfei Wan, Di Zhang, Kun Gai</div>
                            <div class="venue"><em>arXiv:2506.04213</em></div>
                            <div class="publication-links">
                                <a href="https://fulldit2.github.io" target="_blank" rel="noopener noreferrer" class="link-button project">
                                    <i class="fa-solid fa-globe"></i> Project
                                </a>
                                <a href="https://arxiv.org/abs/2506.04213" target="_blank" rel="noopener noreferrer" class="link-button pdf">
                                    <i class="fa-solid fa-file-pdf"></i> PDF
                                </a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/fulldit2.png" alt="Preview for FullDiT2">
                        </div>
                    </li>
                </ul>

                <h3>Conference Papers</h3>
                <ul class="publication-list">
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">StyleMaster: Stylize Your Video with Artistic Generation and Translation</div>
                            <div class="authors"><b>Zixuan Ye</b>, Huijuan Huang, Xintao Wang, Pengfei Wan, Di Zhang, Wenhan Luo</div>
                            <div class="venue"><em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025</em></div>
                            <div class="publication-links">
                                <a href="https://zixuan-ye.github.io/stylemaster/" target="_blank" rel="noopener noreferrer" class="link-button project">
                                    <i class="fa-solid fa-globe"></i> Project
                                </a>
                                <a href="https://arxiv.org/abs/2412.07744" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/KwaiVGI/StyleMaster" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/stylemaster.gif" alt="Preview for StyleMaster">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">Unifying Automatic and Interactive Matting with Pretrained ViTs</div>
                            <div class="authors"><b>Zixuan Ye</b>, Wenze Liu, He Guo, Yujia Liang, Chaoyi Hong, Hao Lu, Zhiguo Cao</div>
                            <div class="venue"><em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</em></div>
                            <div class="publication-links">
                                <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Ye_Unifying_Automatic_and_Interactive_Matting_with_Pretrained_ViTs_CVPR_2024_paper.pdf" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/zixuan-ye/SmartMatting" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/smat.gif" alt="Preview for SmartMatting">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting</div>
                            <div class="authors"><b>Zixuan Ye</b>*, Yutong Dai*, Chaoyi Hong, Zhiguo Cao, Hao Lu</div>
                            <div class="venue"><em>AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2023</em></div>
                            <div class="publication-links">
                                <a href="https://ojs.aaai.org/index.php/AAAI/article/download/25432/25204" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/zixuan-ye/composition_styles" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/comp.png" alt="Preview for Composition Styles">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">SCAPE: A Simple and Strong Category-Agnostic Pose Estimator</div>
                            <div class="authors">Yujia Liang*, <b>Zixuan Ye</b>*, Wenze Liu, Hao Lu</div>
                            <div class="venue"><em>European Conference on Computer Vision (<b>ECCV</b>), 2024</em></div>
                            <div class="publication-links">
                                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03423.pdf" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/tiny-smart/SCAPE" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/scape.png" alt="Preview for SCAPE">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">In-Context Matting</div>
                            <div class="authors">He Guo, <b>Zixuan Ye</b>, Zhiguo Cao, Hao Lu</div>
                            <div class="venue">
                                <em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</em>
                                <span class="venue-award">(Highlight)</span>
                            </div>
                            <div class="publication-links">
                                <a href="https://tiny-smart.github.io/icm.github.io/" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/tiny-smart/in-context-matting" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/icm.png" alt="Preview for In-Context Matting">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">Training Matting Models without Alpha Labels</div>
                            <div class="authors">Wenze Liu, <b>Zixuan Ye</b>, Hao Lu, Zhiguo Cao, Xiangyu Yue</div>
                            <div class="venue">
                                <em>AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2025</em>
                            </div>
                            <div class="publication-links">
                                <a href="https://arxiv.org/abs/2408.10539" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/poppuppy/alpha-free-matting" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/woalpha.png" alt="Preview for Alpha-Free Matting">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">SAPA: Similarity-Aware Point Affiliation for Feature Upsampling</div>
                            <div class="authors">Hao Lu, Wenze Liu, <b>Zixuan Ye</b>, Hongtao Fu, Yuliang Liu, Zhiguo Cao</div>
                            <div class="venue">
                                <em>Neural Information Processing Systems (<b>NeurIPS</b>), 2022</em>
                                <span class="venue-award">(Spotlight)</span>
                            </div>
                            <div class="publication-links">
                                <a href="https://arxiv.org/abs/2209.12866" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                                <a href="https://github.com/tiny-smart/sapa" target="_blank" rel="noopener noreferrer" class="link-button code"><i class="fa-brands fa-github"></i> Code</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/sapa.png" alt="Preview for SAPA">
                        </div>
                    </li>
                    <li class="publication-item">
                        <div class="publication-details">
                            <div class="title">Video Bokeh Rendering: Make Casual Videography Cinematic</div>
                            <div class="authors">Yawen Luo, Min Shi, Liao Shen, Yachuan Huang, <b>Zixuan Ye</b>, Juewen Peng, Zhiguo Cao</div>
                            <div class="venue">
                                <em>ACM International Conference on Multimedia (<b>ACM MM</b>), 2024</em>
                                <span class="venue-award">(Oral, Best Paper Candidate)</span>
                            </div>
                            <div class="publication-links">
                                <a href="https://dlnext.acm.org/doi/pdf/10.1145/3664647.3680629" target="_blank" rel="noopener noreferrer" class="link-button pdf"><i class="fa-solid fa-file-pdf"></i> PDF</a>
                            </div>
                        </div>
                        <div class="publication-media">
                            <img src="paper/vbr.png" alt="Preview for Video Bokeh Rendering">
                        </div>
                    </li>
                </ul>
            </section>
            
            

            <section id="honors">
                <h2><i class="fa-solid fa-trophy"></i> Honors</h2>
                <ul class="honors-list">
                    <li><strong>Hong Kong PhD Fellowship Scheme (HKPFS)</strong>, Hong Kong SAR (2025)</li>
                    <li><strong>HKUST RedBird PhD Award</strong> (2025)</li>
                    <li><strong>China National Scholarship</strong> (2024)</li>
                    <li><strong>Shenzhen Stock Exchange Scholarships for Postgraduates</strong> (2023)</li>
                </ul>
            </section>

        </main>
    </div>

    <script src="script.js"></script>

</body>
</html>